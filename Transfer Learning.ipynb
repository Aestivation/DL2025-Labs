{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113480df",
   "metadata": {},
   "source": [
    "# Lab 4 â€“ CNNs and Transfer Learning\n",
    "\n",
    "This notebook strictly follows the lab instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ac953",
   "metadata": {},
   "source": [
    "## Convolution and Pooling\n",
    "Why: to visualize feature extraction and spatial reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6313f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(img_train, _), _ = keras.datasets.cifar10.load_data()\n",
    "img = tf.image.resize(img_train[0], (224,224))\n",
    "img = tf.expand_dims(tf.cast(img, tf.float32), axis=0)\n",
    "\n",
    "kernel = tf.constant([[-1,0,1],[-1,0,1],[-1,0,1]], dtype=tf.float32)\n",
    "kernel = tf.reshape(kernel, (3,3,1,1))\n",
    "kernel = tf.repeat(kernel, 3, axis=2)\n",
    "\n",
    "conv = tf.nn.conv2d(img, kernel, 1, \"SAME\")\n",
    "max_pool = tf.nn.max_pool2d(conv, 2, 2, \"SAME\")\n",
    "\n",
    "plt.imshow(conv[0]/255); plt.title(\"Convolution\"); plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0eb013",
   "metadata": {},
   "source": [
    "## CNN on Fashion-MNIST\n",
    "Why: baseline image classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train,y_train),(x_test,y_test)=keras.datasets.fashion_mnist.load_data()\n",
    "x_train=x_train/255.0\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(28,28)),\n",
    "    keras.layers.Reshape((28,28,1)),\n",
    "    keras.layers.Conv2D(32,3,activation='relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=3,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f8a20",
   "metadata": {},
   "source": [
    "## Transfer Learning with Xception\n",
    "Why: reuse ImageNet-trained generic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(ds_train,ds_val,_),_=tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:70%]\",\"train[70%:85%]\",\"train[85%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "def preprocess(img,label):\n",
    "    img=tf.image.resize(img,(299,299))\n",
    "    img=keras.applications.xception.preprocess_input(img)\n",
    "    return img,label\n",
    "\n",
    "train_ds=ds_train.map(preprocess).batch(32)\n",
    "val_ds=ds_val.map(preprocess).batch(32)\n",
    "\n",
    "base_model=keras.applications.Xception(weights=\"imagenet\",include_top=False)\n",
    "base_model.trainable=False\n",
    "\n",
    "model=keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(5,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_ds,validation_data=val_ds,epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d1d58",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "Why: demonstrate residual connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46877cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.applications.ResNet50(weights=None).summary()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}