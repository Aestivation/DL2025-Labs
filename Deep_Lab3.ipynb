{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16c9024d",
      "metadata": {
        "id": "16c9024d"
      },
      "source": [
        "# Deep MLP Lab Notebook\n",
        "**Scope:** MNIST LR-finder + MLP, Fashion-MNIST 100-layer activation comparison, CIFAR-10 20-layer DNN (ELU + He) with and without BatchNorm.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "32a0cec8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32a0cec8",
        "outputId": "172ffe95-0f8f-4e6c-e683-e31f15562ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab: installing packages...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    print('Running in Colab: installing packages...')\n",
        "    !pip install -q tensorflow fpdf==1.7.2\n",
        "else:\n",
        "    print('Not in Colab: make sure tensorflow and fpdf are installed in your environment.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n",
        "\n",
        "from fpdf import FPDF\n",
        "import os\n",
        "\n",
        "class LabReportPDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"Deep Learning Lab Report\", ln=True, align=\"C\")\n",
        "        self.ln(3)\n",
        "\n",
        "def save_full_report(sections, output_path=\"/content/full_lab_report.pdf\"):\n",
        "    \"\"\"\n",
        "    sections: dict where\n",
        "        key   = section title (string)\n",
        "        value = section text (string)\n",
        "    \"\"\"\n",
        "    pdf = LabReportPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=10)\n",
        "\n",
        "    for title, text in sections.items():\n",
        "        # Section title\n",
        "        pdf.set_font(\"Arial\", \"B\", 12)\n",
        "        pdf.ln(5)\n",
        "        pdf.cell(0, 8, title, ln=True)\n",
        "        pdf.ln(2)\n",
        "\n",
        "        # Section content\n",
        "        pdf.set_font(\"Arial\", size=11)\n",
        "        pdf.multi_cell(0, 6, text)\n",
        "        pdf.ln(3)\n",
        "\n",
        "    pdf.output(output_path)\n",
        "    print(\"Saved:\", output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE1Y8EClIHMR",
        "outputId": "52bf5cc3-f775-4af4-c08a-a44d65ef715e"
      },
      "id": "SE1Y8EClIHMR",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.12/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8daccf73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8daccf73",
        "outputId": "cc0cd3ed-b24b-4256-b16c-d29a71511a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Output folder: /content/deep_mlp_lab_output\n"
          ]
        }
      ],
      "source": [
        "# Imports and output folder\n",
        "import os, sys, traceback\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks, initializers, optimizers\n",
        "from fpdf import FPDF\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "\n",
        "OUT = Path('/mnt/data/deep_mlp_lab_output') if 'google.colab' not in sys.modules else Path('/content/deep_mlp_lab_output')\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "print('Output folder:', OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7b1ad042",
      "metadata": {
        "id": "7b1ad042"
      },
      "outputs": [],
      "source": [
        "# Utilities: save model summary, quick plotting helpers\n",
        "def save_model_summary(model, filepath):\n",
        "    with open(filepath, 'w', encoding='utf-8') as fh:\n",
        "        model.summary(print_fn=lambda s: fh.write(s + '\\n'))\n",
        "\n",
        "def save_plot(fig, path):\n",
        "    fig.savefig(path, bbox_inches='tight')\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89e21c98",
      "metadata": {
        "id": "89e21c98"
      },
      "source": [
        "## MNIST: LR range test and MLP training\n",
        "\n",
        "This section performs a learning-rate range test (LR finder) and a short training run of an MLP. The LR finder increases the learning rate exponentially each batch and records loss; plot loss vs LR (log-scale) to choose a good LR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "23ca1427",
      "metadata": {
        "id": "23ca1427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f68d07-2f09-46c3-d750-56d0b9bd841a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST and prepare data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train_flat = x_train.reshape((-1, 28*28))\n",
        "x_test_flat = x_test.reshape((-1, 28*28))\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "class LRFinder(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, min_lr=1e-6, max_lr=1, steps=100):\n",
        "        super().__init__()\n",
        "        self.min_lr = min_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.steps = steps\n",
        "        self.batch_count = 0\n",
        "        self.lrs = []      # must be a list!\n",
        "        self.losses = []   # must be a list!\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        self.batch_count += 1\n",
        "\n",
        "        # Progress of LR scan\n",
        "        progress = self.batch_count / self.steps\n",
        "\n",
        "        # Compute new LR\n",
        "        lr = self.min_lr * (self.max_lr / self.min_lr) ** progress\n",
        "\n",
        "        # Update optimizer LR (TF 2.15+ uses learning_rate)\n",
        "        self.model.optimizer.learning_rate.assign(lr)\n",
        "\n",
        "        # Record\n",
        "        self.lrs.append(lr)\n",
        "        self.losses.append(logs[\"loss\"])\n",
        "\n",
        "        # Stop when finished scanning\n",
        "        if self.batch_count >= self.steps:\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "27875612",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "27875612",
        "outputId": "4162ae6e-c942-4e60-d9be-f129d4e796a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.1533 - loss: 2.3021\n",
            "Saved: /content/deep_mlp_lab_output/mnist_lr_finder.png\n"
          ]
        }
      ],
      "source": [
        "# Build a simple MLP and run LR finder (short)\n",
        "def build_mnist_mlp(hidden_units=[512,256,128], dropout=0.2):\n",
        "    inp = keras.Input(shape=(28*28,))\n",
        "    x = inp\n",
        "    for h in hidden_units:\n",
        "        x = layers.Dense(h, activation='relu')(x)\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "    out = layers.Dense(10, activation='softmax')(x)\n",
        "    return keras.Model(inp, out)\n",
        "\n",
        "model = build_mnist_mlp()\n",
        "save_model_summary(model, OUT / 'mnist_model_summary.txt')\n",
        "\n",
        "steps = 600  # reduce for faster runs in Colab free tier if needed\n",
        "lr_finder = LRFinder(min_lr=1e-6, max_lr=1, steps=steps)\n",
        "opt = optimizers.SGD(learning_rate=1e-6)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 128\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_flat, y_train)).shuffle(5000).batch(batch_size).repeat().take(steps)\n",
        "history = model.fit(train_dataset, epochs=1, steps_per_epoch=steps, callbacks=[lr_finder], verbose=1)\n",
        "\n",
        "# Plot LR vs loss\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "ax.plot(lr_finder.lrs, lr_finder.losses)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('Learning Rate (log scale)')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_title('LR range test (MNIST)')\n",
        "save_plot(fig, OUT / 'mnist_lr_finder.png')\n",
        "print('Saved:', OUT / 'mnist_lr_finder.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "46104f31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "46104f31",
        "outputId": "2e107975-bce3-4a07-c47c-f8f14a9316ba",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "422/422 - 14s - 34ms/step - accuracy: 0.9036 - loss: 0.3165 - val_accuracy: 0.9693 - val_loss: 0.1028\n",
            "Epoch 2/12\n",
            "422/422 - 15s - 36ms/step - accuracy: 0.9617 - loss: 0.1286 - val_accuracy: 0.9718 - val_loss: 0.0954\n",
            "Epoch 3/12\n",
            "422/422 - 7s - 17ms/step - accuracy: 0.9715 - loss: 0.0922 - val_accuracy: 0.9797 - val_loss: 0.0677\n",
            "Epoch 4/12\n",
            "422/422 - 8s - 18ms/step - accuracy: 0.9778 - loss: 0.0710 - val_accuracy: 0.9798 - val_loss: 0.0668\n",
            "Epoch 5/12\n",
            "422/422 - 9s - 22ms/step - accuracy: 0.9806 - loss: 0.0610 - val_accuracy: 0.9807 - val_loss: 0.0645\n",
            "Epoch 6/12\n",
            "422/422 - 8s - 18ms/step - accuracy: 0.9842 - loss: 0.0499 - val_accuracy: 0.9830 - val_loss: 0.0645\n",
            "Epoch 7/12\n",
            "422/422 - 7s - 17ms/step - accuracy: 0.9873 - loss: 0.0417 - val_accuracy: 0.9797 - val_loss: 0.0712\n",
            "Epoch 8/12\n",
            "422/422 - 7s - 17ms/step - accuracy: 0.9862 - loss: 0.0424 - val_accuracy: 0.9823 - val_loss: 0.0648\n",
            "Epoch 9/12\n",
            "422/422 - 8s - 18ms/step - accuracy: 0.9882 - loss: 0.0361 - val_accuracy: 0.9845 - val_loss: 0.0667\n",
            "Epoch 10/12\n",
            "422/422 - 9s - 22ms/step - accuracy: 0.9897 - loss: 0.0314 - val_accuracy: 0.9815 - val_loss: 0.0739\n",
            "Epoch 11/12\n",
            "422/422 - 8s - 18ms/step - accuracy: 0.9907 - loss: 0.0295 - val_accuracy: 0.9857 - val_loss: 0.0589\n",
            "Epoch 12/12\n",
            "422/422 - 7s - 17ms/step - accuracy: 0.9911 - loss: 0.0278 - val_accuracy: 0.9830 - val_loss: 0.0668\n",
            "MNIST test_acc: 0.9810000061988831\n"
          ]
        }
      ],
      "source": [
        "# Train MLP on MNIST with chosen LR (example 1e-3) for a few epochs\n",
        "model = build_mnist_mlp()\n",
        "opt = optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "save_model_summary(model, OUT / 'mnist_model_summary_after_lr.txt')\n",
        "\n",
        "hist = model.fit(x_train_flat, y_train, validation_split=0.1, epochs=12, batch_size=128, verbose=2)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(hist.history['loss'], label='train loss')\n",
        "ax.plot(hist.history['val_loss'], label='val loss')\n",
        "ax.plot(hist.history['accuracy'], label='train acc')\n",
        "ax.plot(hist.history['val_accuracy'], label='val acc')\n",
        "ax.legend()\n",
        "ax.set_title('MNIST training curves')\n",
        "save_plot(fig, OUT / 'mnist_training_curves.png')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test_flat, y_test, verbose=0)\n",
        "print('MNIST test_acc:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbbcd9da",
      "metadata": {
        "id": "cbbcd9da"
      },
      "source": [
        "## Fashion-MNIST: 100-layer MLP with different activations\n",
        "\n",
        "We train short runs (3 epochs) of a 100-layer MLP using `sigmoid`, `relu`, `elu`, and `selu`. Expect vanishing gradients for `sigmoid`; SELU may help if using `lecun_normal` and appropriate input scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "64e9634b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64e9634b",
        "outputId": "eb0baad1-627f-42df-d351-0d2f0440f792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Fashion-MNIST shapes: (60000, 784) (60000,)\n"
          ]
        }
      ],
      "source": [
        "# Load Fashion-MNIST and build 100-layer MLP builder\n",
        "(x_train_f, y_train_f), (x_test_f, y_test_f) = keras.datasets.fashion_mnist.load_data()\n",
        "x_train_f = x_train_f.reshape((-1, 28*28)).astype('float32')/255.0\n",
        "x_test_f = x_test_f.reshape((-1, 28*28)).astype('float32')/255.0\n",
        "\n",
        "def build_deep_mlp_100(activation='relu', units=64, use_selu=False):\n",
        "    inp = keras.Input(shape=(28*28,))\n",
        "    x = inp\n",
        "    for i in range(100):\n",
        "        if use_selu:\n",
        "            x = layers.Dense(units, activation='selu', kernel_initializer='lecun_normal')(x)\n",
        "        else:\n",
        "            x = layers.Dense(units, activation=activation, kernel_initializer='he_normal')(x)\n",
        "    out = layers.Dense(10, activation='softmax')(x)\n",
        "    return keras.Model(inp, out)\n",
        "\n",
        "print('Fashion-MNIST shapes:', x_train_f.shape, y_train_f.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bab194f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "bab194f1",
        "outputId": "71de54a5-56f2-4382-8618-1150d4619a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Activation: sigmoid\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "211/211 - 10s - 49ms/step - accuracy: 0.0991 - loss: 2.3383 - val_accuracy: 0.1050 - val_loss: 2.3037\n",
            "Epoch 2/3\n",
            "211/211 - 3s - 14ms/step - accuracy: 0.0978 - loss: 2.3032 - val_accuracy: 0.0942 - val_loss: 2.3028\n",
            "Epoch 3/3\n",
            "211/211 - 4s - 17ms/step - accuracy: 0.0984 - loss: 2.3027 - val_accuracy: 0.0942 - val_loss: 2.3027\n",
            "Saved plot for sigmoid\n",
            "\n",
            "--- Activation: relu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "211/211 - 10s - 45ms/step - accuracy: 0.1670 - loss: 2.2301 - val_accuracy: 0.1962 - val_loss: 2.0046\n",
            "Epoch 2/3\n",
            "211/211 - 3s - 12ms/step - accuracy: 0.2243 - loss: 1.9249 - val_accuracy: 0.1995 - val_loss: 2.1588\n",
            "Epoch 3/3\n",
            "211/211 - 4s - 19ms/step - accuracy: 0.2502 - loss: 1.7909 - val_accuracy: 0.2725 - val_loss: 1.5978\n",
            "Saved plot for relu\n",
            "\n",
            "--- Activation: elu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "211/211 - 12s - 56ms/step - accuracy: 0.0998 - loss: nan - val_accuracy: 0.1050 - val_loss: nan\n",
            "Epoch 2/3\n",
            "211/211 - 3s - 15ms/step - accuracy: 0.0994 - loss: nan - val_accuracy: 0.1050 - val_loss: nan\n",
            "Epoch 3/3\n",
            "211/211 - 3s - 15ms/step - accuracy: 0.0994 - loss: nan - val_accuracy: 0.1050 - val_loss: nan\n",
            "Saved plot for elu\n",
            "\n",
            "--- Activation: selu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "211/211 - 10s - 46ms/step - accuracy: 0.1051 - loss: 2.3170 - val_accuracy: 0.0942 - val_loss: 2.3071\n",
            "Epoch 2/3\n",
            "211/211 - 3s - 15ms/step - accuracy: 0.1001 - loss: 2.3063 - val_accuracy: 0.1008 - val_loss: 2.3042\n",
            "Epoch 3/3\n",
            "211/211 - 4s - 19ms/step - accuracy: 0.1028 - loss: 2.3050 - val_accuracy: 0.1032 - val_loss: 2.3053\n",
            "Saved plot for selu\n"
          ]
        }
      ],
      "source": [
        "# Run short experiments for different activations\n",
        "activations = ['sigmoid','relu','elu','selu']\n",
        "results = {}\n",
        "for act in activations:\n",
        "    print('\\n--- Activation:', act)\n",
        "    use_selu = (act == 'selu')\n",
        "    model_f = build_deep_mlp_100(activation=act if not use_selu else None, units=32, use_selu=use_selu)\n",
        "    model_f.compile(optimizer=optimizers.SGD(learning_rate=1e-2), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    save_model_summary(model_f, OUT / f'fmnist_summary_{act}.txt')\n",
        "    try:\n",
        "        h = model_f.fit(x_train_f, y_train_f, validation_split=0.1, epochs=3, batch_size=256, verbose=2)\n",
        "        results[act] = h.history\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(h.history['loss'], label='train loss')\n",
        "        ax.plot(h.history['val_loss'], label='val loss')\n",
        "        ax.set_title(f'Fashion-MNIST 100-layer ({act})')\n",
        "        ax.legend()\n",
        "        save_plot(fig, OUT / f'fmnist_{act}_loss.png')\n",
        "        print('Saved plot for', act)\n",
        "    except Exception as e:\n",
        "        print('Run failed for', act, e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43434343",
      "metadata": {
        "id": "43434343"
      },
      "source": [
        "## CIFAR-10: 20-layer DNN with ELU + He init\n",
        "\n",
        "We build a fully-connected DNN with 20 hidden layers of ELU units (He initialization). We'll train with Nadam and EarlyStopping, and compare performance with and without Batch Normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a0443628",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0443628",
        "outputId": "77ad4b4c-431d-4f6e-f5c8-943a8b6ba3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR shapes: (50000, 32, 32, 3) (50000,)\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-10(Abbreviation of Canadian Institute For Advanced Research; It s an image dataset )\n",
        "(x_train_c, y_train_c), (x_test_c, y_test_c) = keras.datasets.cifar10.load_data()\n",
        "x_train_c = x_train_c.astype('float32') / 255.0\n",
        "x_test_c = x_test_c.astype('float32') / 255.0\n",
        "y_train_c = y_train_c.flatten()\n",
        "y_test_c = y_test_c.flatten()\n",
        "\n",
        "def build_cifar_dnn(layers_count=20, units=100, use_batchnorm=False):\n",
        "    inp = keras.Input(shape=(32,32,3))\n",
        "    x = layers.Flatten()(inp)\n",
        "    for i in range(layers_count):\n",
        "        x = layers.Dense(units, activation='elu', kernel_initializer=initializers.he_normal())(x)\n",
        "        if use_batchnorm:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "    out = layers.Dense(10, activation='softmax')(x)\n",
        "    return keras.Model(inp, out)\n",
        "\n",
        "print('CIFAR shapes:', x_train_c.shape, y_train_c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a1551bb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "a1551bb6",
        "outputId": "6ff64c30-d9f8-44c4-c6dc-a45221d0947b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== BatchNorm: False\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "176/176 - 16s - 90ms/step - accuracy: 0.2319 - loss: 2.1422 - val_accuracy: 0.2652 - val_loss: 2.0156\n",
            "Epoch 2/8\n",
            "176/176 - 3s - 20ms/step - accuracy: 0.3265 - loss: 1.8421 - val_accuracy: 0.3248 - val_loss: 1.8588\n",
            "Epoch 3/8\n",
            "176/176 - 5s - 27ms/step - accuracy: 0.3631 - loss: 1.7563 - val_accuracy: 0.3734 - val_loss: 1.7131\n",
            "Epoch 4/8\n",
            "176/176 - 3s - 19ms/step - accuracy: 0.3828 - loss: 1.6955 - val_accuracy: 0.4026 - val_loss: 1.6687\n",
            "Epoch 5/8\n",
            "176/176 - 3s - 19ms/step - accuracy: 0.4067 - loss: 1.6423 - val_accuracy: 0.3892 - val_loss: 1.6767\n",
            "Epoch 6/8\n",
            "176/176 - 4s - 25ms/step - accuracy: 0.4218 - loss: 1.6019 - val_accuracy: 0.4250 - val_loss: 1.5952\n",
            "Epoch 7/8\n",
            "176/176 - 3s - 19ms/step - accuracy: 0.4374 - loss: 1.5606 - val_accuracy: 0.4166 - val_loss: 1.6501\n",
            "Epoch 8/8\n",
            "176/176 - 3s - 19ms/step - accuracy: 0.4532 - loss: 1.5291 - val_accuracy: 0.4176 - val_loss: 1.6270\n",
            "Test acc (BN=False): 0.436599999666214\n",
            "\n",
            "=== BatchNorm: True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "176/176 - 29s - 164ms/step - accuracy: 0.3106 - loss: 1.9246 - val_accuracy: 0.3016 - val_loss: 2.0609\n",
            "Epoch 2/8\n",
            "176/176 - 5s - 27ms/step - accuracy: 0.4059 - loss: 1.6552 - val_accuracy: 0.3796 - val_loss: 1.7760\n",
            "Epoch 3/8\n",
            "176/176 - 6s - 33ms/step - accuracy: 0.4447 - loss: 1.5562 - val_accuracy: 0.3684 - val_loss: 1.8115\n",
            "Epoch 4/8\n",
            "176/176 - 5s - 30ms/step - accuracy: 0.4682 - loss: 1.4894 - val_accuracy: 0.4238 - val_loss: 1.6208\n",
            "Epoch 5/8\n",
            "176/176 - 5s - 28ms/step - accuracy: 0.4875 - loss: 1.4383 - val_accuracy: 0.3920 - val_loss: 1.7263\n",
            "Epoch 6/8\n",
            "176/176 - 6s - 33ms/step - accuracy: 0.5042 - loss: 1.3976 - val_accuracy: 0.4386 - val_loss: 1.6049\n",
            "Epoch 7/8\n",
            "176/176 - 13s - 72ms/step - accuracy: 0.5161 - loss: 1.3598 - val_accuracy: 0.4058 - val_loss: 1.6978\n",
            "Epoch 8/8\n",
            "176/176 - 5s - 28ms/step - accuracy: 0.5286 - loss: 1.3286 - val_accuracy: 0.4348 - val_loss: 1.5804\n",
            "Test acc (BN=True): 0.4410000145435333\n"
          ]
        }
      ],
      "source": [
        "# Train CIFAR DNN with Nadam, compare BN on/off\n",
        "for use_bn in [False, True]:\n",
        "    print('\\n=== BatchNorm:', use_bn)\n",
        "    model_c = build_cifar_dnn(layers_count=20, units=64, use_batchnorm=use_bn)\n",
        "    save_model_summary(model_c, OUT / f'cifar_summary_{\"bn\" if use_bn else \"nobn\"}.txt')\n",
        "    model_c.compile(optimizer=optimizers.Nadam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    es = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    try:\n",
        "        h = model_c.fit(x_train_c, y_train_c, validation_split=0.1, epochs=8, batch_size=256, callbacks=[es], verbose=2)\n",
        "        fig, ax = plt.subplots(figsize=(6,4))\n",
        "        ax.plot(h.history['loss'], label='train loss')\n",
        "        ax.plot(h.history['val_loss'], label='val loss')\n",
        "        ax.plot(h.history['accuracy'], label='train acc')\n",
        "        ax.plot(h.history['val_accuracy'], label='val acc')\n",
        "        ax.legend()\n",
        "        ax.set_title(f'CIFAR10 DNN (BN={use_bn})')\n",
        "        save_plot(fig, OUT / f'cifar_dnn_bn_{use_bn}.png')\n",
        "        test_loss, test_acc = model_c.evaluate(x_test_c, y_test_c, verbose=0)\n",
        "        print('Test acc (BN={}):'.format(use_bn), test_acc)\n",
        "    except Exception as e:\n",
        "        print('CIFAR run failed (BN={}):'.format(use_bn), e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "068d9fd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "068d9fd2",
        "outputId": "2b1a2b6b-93dc-4dcb-b540-a7982e7945bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PDF report to: /content/deep_mlp_lab_output/lab_report_short.pdf\n"
          ]
        }
      ],
      "source": [
        "# Compile a short PDF report with the generated images and console snippets\n",
        "pdf = FPDF(orientation='P', unit='mm', format='A4')\n",
        "pdf.set_auto_page_break(auto=True, margin=10)\n",
        "pdf.add_page()\n",
        "pdf.set_font('Arial', size=12)\n",
        "pdf.cell(0, 6, 'Lab report: Deep MLP experiments (29 Nov 2025 - 9 Dec 2025)', ln=True)\n",
        "pdf.ln(2)\n",
        "pdf.set_font('Arial', size=10)\n",
        "pdf.multi_cell(0, 5, 'This PDF contains plots produced by the automated runs. Re-run longer experiments for final submission.')\n",
        "\n",
        "def add_image_if_exists(p: Path, w=180):\n",
        "    if p.exists():\n",
        "        pdf.add_page()\n",
        "        pdf.set_font('Arial', size=11)\n",
        "        pdf.cell(0,6, p.name, ln=True)\n",
        "        pdf.image(str(p), w=w)\n",
        "\n",
        "images = ['mnist_lr_finder.png','mnist_training_curves.png'] + [f'fmnist_{a}_loss.png' for a in ['sigmoid','relu','elu','selu']] + [f'cifar_dnn_bn_{b}.png' for b in [False, True]]\n",
        "for img in images:\n",
        "    add_image_if_exists(OUT / img)\n",
        "\n",
        "pdf.add_page()\n",
        "pdf.set_font('Arial', size=10)\n",
        "pdf.cell(0,6, 'Note: console outputs and model summaries are saved as text files in the output folder.', ln=True)\n",
        "\n",
        "report_path = OUT / 'lab_report_short.pdf'\n",
        "pdf.output(str(report_path))\n",
        "print('Saved PDF report to:', report_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yecsBfmHF9D_",
        "outputId": "eae0f79a-6a85-4db0-f43e-d24e6e126310"
      },
      "id": "yecsBfmHF9D_",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content:\n",
            "deep_mlp_lab_output  sample_data\n",
            "\n",
            "/content/deep_mlp_lab_output:\n",
            "cifar_dnn_bn_False.png\t fmnist_summary_relu.txt\n",
            "cifar_dnn_bn_True.png\t fmnist_summary_selu.txt\n",
            "cifar_summary_bn.txt\t fmnist_summary_sigmoid.txt\n",
            "cifar_summary_nobn.txt\t lab_report_short.pdf\n",
            "fmnist_elu_loss.png\t mnist_lr_finder.png\n",
            "fmnist_relu_loss.png\t mnist_model_summary_after_lr.txt\n",
            "fmnist_selu_loss.png\t mnist_model_summary.txt\n",
            "fmnist_sigmoid_loss.png  mnist_training_curves.png\n",
            "fmnist_summary_elu.txt\n",
            "\n",
            "/content/sample_data:\n",
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}